Key learnings:
RAG architecture: Load → Chunk → Embed → Store → Retrieve → Answer.
Modularity: Each component is swappable (models, databases, prompts).
LangChain Ecosystem: Text splitters, vector stores, document loaders, chains.
FAISS Usage: Efficient similarity search with OpenAI embeddings.
End-to-end Search + Q&A pipeline.